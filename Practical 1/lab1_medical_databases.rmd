---
title: Health Data Science Practical 1
author: Jenna Hepburn
date: May 28, 2023
output:
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)          # Data Input
library(tidymodels)     # Data Manipulation
library(tidyverse)      # Data Manipulation
library(lubridate)      # Data Manupulation
library(dplyr)          # Data Manipulation
library(reshape2)       # Data Manipulation
library(caTools)        # Data Manipulation
library(corrplot)       # Data Visualisation
library(ggplot2)        # Data Visualization
library(viridis)        # Data Visualization
library(ggthemes)       # Data Visualization
library(pROC)           # Metrics
library(caret)          # Machine Learning
library(ranger)         # Machine Learning
library(e1071)          # Machine Learning
library (randomForest)  # Machine Learning
```

This practical is based on exploratory data analysis and prediction of a dataset derived from a municipal database of healthcare administrative data. This dataset is derived from Vitoria, the capital city of Espírito Santo, Brazil (population 1.8 million) and was freely shared under a creative commons license.

**Generate an rmarkdown report that contains all the necessary code to document and perform: EDA, prediction of no-shows using XGBoost, and an analysis of variable/feature importance using this data set. Ensure your report includes answers to any questions marked in bold. Please submit your report via brightspace as a link to a git repository containing the rmarkdown and compiled/knitted html version of the notebook.**

## Introduction

The Brazilian public health system, known as SUS for Unified Health System in its acronym in Portuguese, is one of the largest health system in the world, representing government investment of more than 9% of GDP. However, its operation is not homogeneous and there are distinct perceptions of quality from citizens in different regions of the country.  Non-attendance of medical appointments contributes a significant additional burden on limited medical resources.  This analysis will try and investigate possible factors behind non-attendance using an administrative database of appointment data from Vitoria, Espírito Santo, Brazil.

The data required is available via the [course website](https://github.com/maguire-lab/health_data_science_research/tree/master/static_files/practicals/lab1_data).

### Understanding the data

**1** Use the data dictionary describe each of the variables/features in the CSV in your report.

PatientID - Number for each patient that uniquely identifies them.

AppointmentID - Number for each appointment that uniquely identifies it.

Gender - Patient gender (Male or Female).

ScheduledDate - Date that the patient scheduled the appointment.

AppointmentDate - Date the appointment occurred.

Age - Patient age at time of appointment.

Neighbourhood - The neighbourhood/district of Vitória (capital city of Espírito Santo, Brazil) in which the appointment occurred.

SocialWelfare - Binary indicator of whether the patient is a recipient of Bolsa Família welfare payments, which are welfare payments of the country of Brazil for people who fall below the poverty line.

Hypertension - Binary indicator of whether the patient has been diagnosed with hypertension.

Diabetes - Binary indicator of whether the patient has been diagnosed with diabetes.

AlcoholUseDisorder - Binary indicator of whether the patient has been diagnosed with alcohol use disorder.

Disability - Whether the patient previously diagnosed with a disability. 0 value if no disability and severity rating of 1-4 if the patient has a disability.

SMSReceived - Binary indicator of whether a reminder text sent to the patient before appointment.

NoShow - Indicator of whether the patient attended scheduled appointment (yes/no).

**2** Can you think of 3 hypotheses for why someone may be more likely to miss a medical appointment?

- Unable to get time off work to attend appointment as medical appointments typically happen during weekday working hours which may be a barrier for people to attend. 

- Disability or chronic illness could make it difficult for patients to physically make it to appointments.

- Transportation issues including not having a vehicle, not being able to afford public transit, or improper, unavailable, or unsafe public transit.

**3** Can you provide 3 examples of important contextual information that is missing in this data dictionary and dataset that could impact your analyses e.g., what type of medical appointment does each `AppointmentID` refer to?  

- More information on comorbidities such as chronic illnesses and diagnoses other than the 4 included (hypertension, diabetes, alcohol use disorder, and disability)

- Access to a vehicle

- Level of educational attainment or socioeconomic status

- Hospitalizations

## Data Parsing and Cleaning

**4** Modify the following to make it reproducible i.e., downloads the data file directly from version control

```{r parse}
raw.data <- read_csv('2016_05v2_VitoriaAppointmentData.csv', col_types='fffTTifllllflf')

raw.data <- readr::read_csv('https://raw.githubusercontent.com/jennahepburn/healthdatasci/main/Practical%201/2016_05v2_VitoriaAppointmentData.csv', col_types='fffTTifllllflf')
```

Now we need to check data is valid: because we specified col_types and the data parsed without error most of our data seems to at least be formatted as we expect i.e., ages are integers

```{r}
raw.data %>% filter(Age > 110)
```
We can see there are 2 patient's older than 100 which seems suspicious but we can't actually say if this is impossible.

**5** Are there any individuals with impossible ages? If so we can drop this row using `filter` i.e., `data <- data %>% filter(CRITERIA)`

There are two individuals who are 115 years old. This is on the edge of being biologically plausible, as the oldest ever person lived to 122 years old. However, while this may seem unlikely, 115 is not old enough to be biologically impossible. Therefore, I will not drop these patients.

## Exploratory Data Analysis
First, we should get an idea if the data meets our expectations, there are newborns in the data (`Age==0`) and we wouldn't expect any of these to be diagnosed with Diabetes, Alcohol Use Disorder, and Hypertension (although in theory it could be possible).  We can easily check this:

```{r}
raw.data %>% filter(Age == 0) %>% select(Hypertension, Diabetes, AlcoholUseDisorder) %>% unique()
```

We can also explore things like how many different neighborhoods are there and how many appoints are from each? 

```{r}
count(raw.data, Neighbourhood, sort = TRUE)
```
**6** What is the maximum number of appointments from the same patient?

```{r}
count(raw.data, PatientID, sort = TRUE)

raw.data %>% filter(PatientID == 822145925426128) %>% unique()
```

The max number of appointments booked by the same patient is 88. However, it appears he did not show up to most of the appointments. He attended 3 of the 88 booked appointments.

Let's explore the correlation between variables:

```{r}
# let's define a plotting function
corplot = function(df){
  
  cor_matrix_raw <- round(cor(df),2)
  cor_matrix <- melt(cor_matrix_raw)
  
  
  #Get triangle of the correlation matrix
  #Lower Triangle
  get_lower_tri<-function(cor_matrix_raw){
    cor_matrix_raw[upper.tri(cor_matrix_raw)] <- NA
    return(cor_matrix_raw)
  }
  
  # Upper Triangle
  get_upper_tri <- function(cor_matrix_raw){
    cor_matrix_raw[lower.tri(cor_matrix_raw)]<- NA
    return(cor_matrix_raw)
  }
  
  upper_tri <- get_upper_tri(cor_matrix_raw)
  
  # Melt the correlation matrix
  cor_matrix <- melt(upper_tri, na.rm = TRUE)
  
  # Heatmap Plot
  cor_graph <- ggplot(data = cor_matrix, aes(Var2, Var1, fill = value))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "darkorchid", high = "orangered", mid = "grey50", 
                         midpoint = 0, limit = c(-1,1), space = "Lab", 
                         name="Pearson\nCorrelation") +
    theme_minimal()+ 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                     size = 8, hjust = 1))+
    coord_fixed()+ geom_text(aes(Var2, Var1, label = value), color = "black", size = 2) +
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      panel.grid.major = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      axis.ticks = element_blank())+
      ggtitle("Correlation Heatmap")+
      theme(plot.title = element_text(hjust = 0.5))
  
  cor_graph
}

numeric.data = mutate_all(raw.data, function(x) as.numeric(x))

# Plot Correlation Heatmap
corplot(numeric.data)
```

Correlation heatmaps are useful for identifying linear relationships between variables/features.
In this case, we are particularly interested in relationships between `NoShow` and any specific variables.

**7** Which parameters most strongly correlate with missing appointments (`NoShow`)?

The variables that are most strongly correlated with missing appointments are SMSReceived and ScheduledDate.

**8** Are there any other variables which strongly correlate with one another?

No variables are overly highly correlated with each other, however, based on the heat map scale, we will consider correlations greater than or equal to $\pm 0.5$ as a strong correlation.

- Appointment ID and patient ID
- Appointment ID and appointment date
- Appointment date and scheduled date
- Age and hypertension

**9** Do you see any issues with PatientID/AppointmentID being included in this plot? 

Yes, I do not think patient ID and appointment ID should be included in this plot as they are dependent on each other and therefore expected to be correlated. Appointment IDs will only ever have 1 patient ID associated with it. Additionally, there is no useful information to be gained from these values as they are randomly generated and cannot give us any prediction power to determine something such as missing an appointment. 

Let's look at some individual variables and their relationship with `NoShow`.

```{r,fig.align="center"}
ggplot(raw.data) + 
  geom_density(aes(x=Age, fill=NoShow), alpha=0.8) + 
  ggtitle("Density of Age by Attendence")
```
There does seem to be a difference in the distribution of ages of people that miss and don't miss appointments.  
However, the shape of this distribution means the actual correlation is near 0 in the heatmap above. This highlights the need to look at individual variables.

Let's take a closer look at age by breaking it into categories.

```{r, fig.align="center"}
raw.data <- raw.data %>% mutate(Age.Range=cut_interval(Age, length=10))

ggplot(raw.data) + 
  geom_bar(aes(x=Age.Range, fill=NoShow)) + 
  ggtitle("Amount of No Show across Age Ranges")

ggplot(raw.data) + 
  geom_bar(aes(x=Age.Range, fill=NoShow), position='fill') + 
  ggtitle("Proportion of No Show across Age Ranges")
```

**10** How could you be misled if you only plotted 1 of these 2 plots of attendance by age group?

If I had only plotted the second plot, it may seem that there was a large number of individuals no-showing appointments. For example, there are only 2 individuals (5 appointments) for the 110-120 age group, but one of the individuals missed 3 of 4 appointments. These 3 of 5 missed appointments for this age group makes it look like a massive burden of no-showed appointments, but in reality the effect is fairly small since there are only 2 individuals represented in this age group. This is much better represented in the first plot, which demonstrates the size of the groups to better understand the effect size. Additionally, trends are more easily seen with the first plot, which shows the no-shows appear to decrease with age starting at age 40-50.

The key takeaway from this is that  number of individuals > 90 are very few from plot 1 so probably are very small so unlikely to make much of an impact on the overall distributions. 
However, other patterns do emerge such as 10-20 age group is nearly twice as likely to miss appointments as the 60-70 years old.

Another interesting finding is the `NA` group, they are the result of trying to assign age of 0 to groups and represent missing data.

```{r}
raw.data %>% filter(Age == 0) %>% count()
```

Next, we'll have a look at `SMSReceived` variable:

```{r,fig.align="center"}
ggplot(raw.data) + 
  geom_bar(aes(x=SMSReceived, fill=NoShow), alpha=0.8) + 
  ggtitle("Density of SMS received across Age and No Show")

ggplot(raw.data) + 
  geom_bar(aes(x=SMSReceived, fill=NoShow), position='fill', alpha=0.8) + 
  ggtitle("Density of SMS received across Age and No Show")
```


**11** From this plot does it look like SMS reminders increase or decrease the chance of someone not attending an appointment? Why might the opposite actually be true (hint: think about biases)? 

It appears that receiving an SMS reminder reduces the chances of attending an appointment. However, this may not be entirely accurate. Firstly, from the previous question, we can see that age groups under 40 are more likely to miss an appointment. This younger age group would also be more likely to have a cell phone to receive SMS reminders compared to older ages. Additionally, same day appointments or walk-in appointments would likely not send patients a reminder. If an appointment is booked same day or through walk-in, the patient would be less likely to miss the appointment, despite not receiving a reminder. These factors may bias the results we see with the graphs.

**12** Create a similar plot which compares the the density of `NoShow` across the values of disability 

```{r,fig.align="center"}
ggplot(raw.data) + 
  geom_bar(aes(x=Disability, fill=NoShow), alpha=0.8) + 
  ggtitle("Density of No Show by Disability Status/Severity")

ggplot(raw.data) + 
  geom_bar(aes(x=Disability, fill=NoShow), position='fill', alpha=0.8) + 
  ggtitle("Density of No Show by Disability Status/Severity")
```

Most neighborhoods have similar proportions of no-show but some have much higher and lower rates.

**13** Suggest a reason for differences in attendance rates across neighbourhoods.

Differences in attendance by neighbourhood may be explained by differences in socioeconomic status by location. Often in research postal code or location can be used as a proxy for socioeconomic status, and this may be valid in this case as well. There may also be differences in distance to a medical clinic by neighbourhood that makes it more difficult to attend appointments due to increased transportation and time requirements. 

Now let's explore the relationship between gender and NoShow.
```{r, fig.align="center"}
ggplot(raw.data) + 
  geom_bar(aes(x=Gender, fill=NoShow)) +
  ggtitle("Gender by Attendance")

ggplot(raw.data) + 
  geom_bar(aes(x=Gender, fill=NoShow), position='fill') +
  ggtitle("Gender by Attendance")
```

**14** Create a similar plot using `SocialWelfare`

```{r ,fig.align="center"}
ggplot(raw.data) + 
  geom_bar(aes(x=SocialWelfare, fill=NoShow)) +
  ggtitle("Attendance by Social Welfare")

ggplot(raw.data) + 
  geom_bar(aes(x=SocialWelfare, fill=NoShow), position='fill') +
  ggtitle("Attendance by Social Welfare")
```

Far more exploration could still be done, including dimensionality reduction approaches but although we have found some patterns there is no major/striking patterns on the data as it currently stands.

However, maybe we can generate some new features/variables that more strongly relate to the `NoShow`.

## Feature Engineering

Let's begin by seeing if appointments on any day of the week has more no-show's. Fortunately, the `lubridate` library makes this quite easy!

```{r}
raw.data <- raw.data %>% mutate(AppointmentDay = wday(AppointmentDate, label=TRUE, abbr=TRUE), 
                                 ScheduledDay = wday(ScheduledDate,  label=TRUE, abbr=TRUE))

ggplot(raw.data) +
  geom_bar(aes(x=AppointmentDay, fill=NoShow)) +
  ggtitle("Amount of No Show across Appointment Day") 

ggplot(raw.data) +
  geom_bar(aes(x=AppointmentDay, fill=NoShow), position = 'fill') +
  ggtitle("Amount of No Show across Appointment Day") 
```
Let's begin by creating a variable called `Lag`, which is the difference between when an appointment was scheduled and the actual appointment.

```{r, fig.align="center"}
raw.data <- raw.data %>% mutate(Lag.days=difftime(AppointmentDate, ScheduledDate, units = "days"),
                                Lag.hours=difftime(AppointmentDate, ScheduledDate, units = "hours"))

ggplot(raw.data) + 
  geom_density(aes(x=Lag.days, fill=NoShow), alpha=0.7)+
  ggtitle("Density of Lag (days) by attendance")
```

**15** Have a look at the values in lag variable, does anything seem odd?

Yes, it seems odd that that a huge portion of the patients that showed up to their appointment had 0 days between making the appointment and attending the appointment. This makes me think that some of these visits were likely walk-in visits (which by nature have a 0% no-show rate), or same day booking which would likely have a reduced rate of no-shows compared to appointments booked ahead of time.

## Predictive Modeling

Let's see how well we can predict NoShow from the data. 

We'll start by preparing the data, followed by splitting it into testing and training set, modeling and finally, evaluating our results. For now we will subsample but please run on full dataset for final execution.


```{r}
data.prep <- raw.data %>% select(-AppointmentID, -PatientID)

set.seed(42)
data.split <- initial_split(data.prep, prop = 0.7)
train  <- training(data.split)
test <- testing(data.split)
```

Let's now set the cross validation parameters, and add classProbs so we can use AUC as a metric for xgboost.

```{r}
fit.control <- trainControl(method="cv",number=3,
                           classProbs = TRUE, summaryFunction = twoClassSummary)
```

**16** Based on the EDA, how well do you think this is going to work?

Based on the issues and biases we identified in previous questions including effect of walk-in appointments, missing info that may be important, bias in SMS reminders, etc., it is likely that this model will also be biased and therefore not overly effective as a predictive tool. However, there are over 110,000 observations which is a large dataset to base this off of, which may work in favour of the model despite potential bias. 

Now we can train our XGBoost model
```{r}
xgb.grid <- expand.grid(eta=c(0.05),
                       max_depth=c(4),colsample_bytree=1,
                       subsample=1, nrounds=500, gamma=0, min_child_weight=5)

xgb.model <- train(NoShow ~ .,data=train, method="xgbTree",metric="ROC",
                  tuneGrid=xgb.grid, trControl=fit.control)

xgb.pred <- predict(xgb.model, newdata=test)
xgb.probs <- predict(xgb.model, newdata=test, type="prob")
```

```{r}
test <- test %>% mutate(NoShow.numerical = ifelse(NoShow=="Yes",1,0))
confusionMatrix(xgb.pred, test$NoShow, positive="Yes")
paste("XGBoost Area under ROC Curve: ", round(auc(test$NoShow.numerical, xgb.probs[,2]),3), sep="")
```

This isn't an unreasonable performance, but let's look a bit more carefully at the correct and incorrect predictions,

```{r ,fig.align="center"}
xgb.probs$Actual = test$NoShow.numerical
xgb.probs$ActualClass = test$NoShow
xgb.probs$PredictedClass = xgb.pred
xgb.probs$Match = ifelse(xgb.probs$ActualClass == xgb.probs$PredictedClass,
                         "Correct","Incorrect")
# [4.8] Plot Accuracy
xgb.probs$Match = factor(xgb.probs$Match,levels=c("Incorrect","Correct"))
ggplot(xgb.probs,aes(x=Yes,y=Actual,color=Match))+
  geom_jitter(alpha=0.2,size=0.25)+
  scale_color_manual(values=c("grey40","orangered"))+
  ggtitle("Visualizing Model Performance", "(Dust Plot)")
```


Finally, let's close it off with the variable importance of our model:

```{r,fig.align="center"}
results = data.frame(Feature = rownames(varImp(xgb.model)$importance)[1:10],
                     Importance = varImp(xgb.model)$importance[1:10,])

results$Feature = factor(results$Feature,levels=results$Feature)


# [4.10] Plot Variable Importance
ggplot(results, aes(x=Feature, y=Importance,fill=Importance))+
  geom_bar(stat="identity")+
  scale_fill_gradient(low="grey20",high="orangered")+
  ggtitle("XGBoost Variable Importance")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**17** Using the [caret package](https://topepo.github.io/caret/) fit and evaluate 1 other ML model on this data.

```{r}
train.ctl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10)

d.tree <- train(NoShow ~ .,
                data = train,
                method = "rpart",
                trControl = train.ctl)

d.tree
```

**18** Based on everything, do you think we can trust analyses based on this dataset? Explain your reasoning.

Based on everything, I think this data has severe limitations that affect the usefulness and accuracy of our results. The fact that there are both walk-in and booked appointments in this dataset add a challenge for our models, as all predictors may not be applicable for both types of appointments (ex. SMS reminder). The models perform decently given the quality of the data, but I do not believe these analyses can be trusted at face value. It is important to interpret these models with caution, and clearly outline the limitations that we have discussed. 

## Credits

This notebook was based on a combination of other notebooks e.g., [1](https://www.kaggle.com/code/tsilveira/applying-heatmaps-for-categorical-data-analysis), [2](https://www.kaggle.com/code/samratp/predict-show-noshow-eda-visualization-model), [3](https://www.kaggle.com/code/andrewmvd/exploring-and-predicting-no-shows-with-xgboost/report)